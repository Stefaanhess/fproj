{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports,  Settings and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = 'no_batchnorm_096_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Code.Models.c7o2h10_model import DeepPotential, normalize, backtransform\n",
    "from Code.Models.api import Network\n",
    "from Code.Models.nn_extentions import AbcExponentialLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './Dataset/c7o2h10_X.npy'\n",
    "label_path = './Dataset/c7o2h10_Y.npy'\n",
    "train_ids_path = './Dataset/iso17/train_ids.txt'\n",
    "test_ids_path = './Dataset/iso17/validation_ids.txt'\n",
    "eval_path = './evaluation/c7o2h10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use cuda:   True\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print('use cuda:  ', use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = (np.loadtxt(train_ids_path) - 1).astype(int).tolist()\n",
    "test_ids = (np.loadtxt(test_ids_path) - 1).astype(int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_npy = np.load(data_path)\n",
    "Y_npy = np.load(label_path) * -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instanciate and create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mi/stefaah94/miniconda3/lib/python3.6/site-packages/torch/cuda/__init__.py:116: UserWarning: \n",
      "    Found GPU1 NVS 310 which is of cuda capability 2.1.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    }
   ],
   "source": [
    "model = DeepPotential(use_cuda=use_cuda,\n",
    "                      eval_path=eval_path,\n",
    "                      comment=comment)\n",
    "network = Network(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network.create_dataloaders(X_npy, Y_npy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\tprogress: 0.0\ttime estimate: 281.13\ttrain loss: 0.00369\ttest loss: 0.001834\n",
      "epoch: 2\tprogress: 0.01\ttime estimate: 286.4\ttrain loss: 0.00152\ttest loss: 0.001394\n",
      "epoch: 3\tprogress: 0.01\ttime estimate: 284.71\ttrain loss: 0.001395\ttest loss: 0.001266\n",
      "epoch: 4\tprogress: 0.01\ttime estimate: 290.81\ttrain loss: 0.001284\ttest loss: 0.001188\n",
      "epoch: 5\tprogress: 0.01\ttime estimate: 283.89\ttrain loss: 0.001199\ttest loss: 0.001702\n",
      "epoch: 6\tprogress: 0.02\ttime estimate: 273.57\ttrain loss: 0.001148\ttest loss: 0.001159\n",
      "epoch: 7\tprogress: 0.02\ttime estimate: 270.63\ttrain loss: 0.001087\ttest loss: 0.00102\n",
      "epoch: 8\tprogress: 0.02\ttime estimate: 268.89\ttrain loss: 0.001056\ttest loss: 0.000991\n",
      "epoch: 9\tprogress: 0.03\ttime estimate: 268.7\ttrain loss: 0.001019\ttest loss: 0.000988\n",
      "epoch: 10\tprogress: 0.03\ttime estimate: 270.64\ttrain loss: 0.000987\ttest loss: 0.00104\n",
      "epoch: 11\tprogress: 0.03\ttime estimate: 267.26\ttrain loss: 0.000964\ttest loss: 0.000924\n",
      "epoch: 12\tprogress: 0.03\ttime estimate: 267.34\ttrain loss: 0.000939\ttest loss: 0.00092\n",
      "epoch: 13\tprogress: 0.04\ttime estimate: 268.68\ttrain loss: 0.000928\ttest loss: 0.000905\n",
      "epoch: 14\tprogress: 0.04\ttime estimate: 269.99\ttrain loss: 0.000901\ttest loss: 0.000964\n"
     ]
    }
   ],
   "source": [
    "network.fit(350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11613484221795595"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = network.calculate_test_mae()\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.model.train()\n",
    "latent, labels = [], []\n",
    "for x, y in network.test_loader:\n",
    "    if network.model.use_cuda:\n",
    "        x = x.cuda()\n",
    "    pred = network.model(x)\n",
    "    latent.append(pred.detach().cpu())\n",
    "    labels.append(y)\n",
    "latent = torch.cat(latent).data\n",
    "labels = torch.cat(labels).data\n",
    "latent = backtransform(latent, network.y_min, network.y_max).squeeze()\n",
    "labels = backtransform(labels, network.y_min, network.y_max).squeeze()\n",
    "abs(latent - labels).mean().numpy().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mi/stefaah94/miniconda3/lib/python3.6/site-packages/matplotlib/figure.py:459: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    }
   ],
   "source": [
    "network.show_loss_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0018338283355703135,\n",
       " 0.0013941265390771162,\n",
       " 0.0012660046944749535,\n",
       " 0.0011876590809211714,\n",
       " 0.001702100103271496,\n",
       " 0.0011585739846192,\n",
       " 0.0010197210661341061,\n",
       " 0.0009914807337863241,\n",
       " 0.0009881184978099641,\n",
       " 0.0010401033244637713,\n",
       " 0.0009236517092360747,\n",
       " 0.0009204263283059184,\n",
       " 0.0009046287254951793,\n",
       " 0.0009643610832945044,\n",
       " 0.0008893155767784528,\n",
       " 0.0008484323987461139,\n",
       " 0.0008342010417922112,\n",
       " 0.0008123710466489397,\n",
       " 0.0008336759036716133,\n",
       " 0.0008064939450719794,\n",
       " 0.000789872525883421,\n",
       " 0.0008005098684657103,\n",
       " 0.0007642604056487983,\n",
       " 0.0007497807669346105,\n",
       " 0.0007885259087687605,\n",
       " 0.0007596226030032728,\n",
       " 0.0009846253572493907,\n",
       " 0.0007337735676942469,\n",
       " 0.0007052968303967013,\n",
       " 0.0006980309181904866,\n",
       " 0.0007209450830468897,\n",
       " 0.0007007978517495672,\n",
       " 0.0008072582140892017,\n",
       " 0.0006747027115083328,\n",
       " 0.0007437636275757219,\n",
       " 0.000746735755835384,\n",
       " 0.000732845371761718,\n",
       " 0.0006878047683206287,\n",
       " 0.0006573638330889863,\n",
       " 0.0006661689063140115,\n",
       " 0.0007658668999888237,\n",
       " 0.0006393768362305016,\n",
       " 0.0006276188365219273,\n",
       " 0.0006919386247095407,\n",
       " 0.000622673253256007,\n",
       " 0.0006296958760964878,\n",
       " 0.0006250150260832297,\n",
       " 0.0006544438719871717,\n",
       " 0.0006182492131930154,\n",
       " 0.0006667816799642635,\n",
       " 0.0006010211089503139,\n",
       " 0.0006062430580399145,\n",
       " 0.000614781312467313,\n",
       " 0.0006685706796803867,\n",
       " 0.0006194565709601683,\n",
       " 0.0006730267158312152,\n",
       " 0.0005877072296217819,\n",
       " 0.0006017858713349881,\n",
       " 0.0005952395677940286,\n",
       " 0.0006136364459247129,\n",
       " 0.0005951858506872829,\n",
       " 0.0005685203358059043,\n",
       " 0.0005793066303612659,\n",
       " 0.0005882994183999637,\n",
       " 0.0005642609435115922,\n",
       " 0.0006839186498003666,\n",
       " 0.0005673507033509026,\n",
       " 0.0005588412245573803,\n",
       " 0.0006913854022378668,\n",
       " 0.0005977996927351383,\n",
       " 0.0005595977095900971,\n",
       " 0.0006204367123026931,\n",
       " 0.0005857460059563133,\n",
       " 0.0005612898399720109,\n",
       " 0.0005493631993951483,\n",
       " 0.0005746985261201366,\n",
       " 0.0005515393144887758,\n",
       " 0.0005474406307748279,\n",
       " 0.0005570926937560461,\n",
       " 0.0005515723387995896,\n",
       " 0.000542047754869963,\n",
       " 0.0005471658883016222,\n",
       " 0.000540377374022895,\n",
       " 0.0005577581382021037,\n",
       " 0.00053349652142919,\n",
       " 0.0005437907331011688,\n",
       " 0.0005516884176746175,\n",
       " 0.0005339588554289177,\n",
       " 0.0005665584400543489,\n",
       " 0.0005250513174517829,\n",
       " 0.0005627908370323257,\n",
       " 0.000526229004764639,\n",
       " 0.0005226791297855336,\n",
       " 0.0005594342349951616,\n",
       " 0.0005166464887368678,\n",
       " 0.0005223139307705381,\n",
       " 0.0005186930138864135,\n",
       " 0.0005472285464723893,\n",
       " 0.0005321106351319256,\n",
       " 0.000513632376776063,\n",
       " 0.0005134889875893579,\n",
       " 0.0005124109913421458,\n",
       " 0.000518313583893368,\n",
       " 0.0005131019352656987,\n",
       " 0.0005842917304186102,\n",
       " 0.0005573328098839608,\n",
       " 0.0005108384893677967,\n",
       " 0.0005184060746057752,\n",
       " 0.0005127106076652836,\n",
       " 0.0005475332448206539,\n",
       " 0.0005070096509136236,\n",
       " 0.0005082354512967563,\n",
       " 0.0005283513783039815,\n",
       " 0.0005165216373657428,\n",
       " 0.0005263669585547494,\n",
       " 0.0005054259910622093,\n",
       " 0.0005064534198514258,\n",
       " 0.0005160696464533471,\n",
       " 0.0005139176282792626,\n",
       " 0.0005066235678083481,\n",
       " 0.0005139086619298193,\n",
       " 0.0005243562176063041,\n",
       " 0.0005003895786788463,\n",
       " 0.000506292901691189,\n",
       " 0.0004966377031586043,\n",
       " 0.0005036769453838475,\n",
       " 0.0005120864388766919,\n",
       " 0.0004983290478824872,\n",
       " 0.0005036031451089017,\n",
       " 0.0005210459581088164,\n",
       " 0.0004938174103088915,\n",
       " 0.0004947537574615639,\n",
       " 0.0005048764712046064,\n",
       " 0.000495696391018682,\n",
       " 0.0004922190612663158,\n",
       " 0.0004935991644365649,\n",
       " 0.0005017394364810296,\n",
       " 0.0004999425250990396,\n",
       " 0.0004924763831704157,\n",
       " 0.0004936460571253916,\n",
       " 0.0004936928585290064,\n",
       " 0.0005012109011141455,\n",
       " 0.0005044385017765889,\n",
       " 0.0004958378855781249,\n",
       " 0.0004883698685648521,\n",
       " 0.0004910327626852435,\n",
       " 0.0004938386783901853,\n",
       " 0.0004897604680686506,\n",
       " 0.0004909501982943452,\n",
       " 0.0005147522384435152,\n",
       " 0.0004906647058867797,\n",
       " 0.00048656003621618584,\n",
       " 0.0004861329997141386,\n",
       " 0.0005009537406333074,\n",
       " 0.0004855191174421562,\n",
       " 0.0004867807706622249,\n",
       " 0.0004874168322709616,\n",
       " 0.0004886081928383539,\n",
       " 0.0004874810786060371,\n",
       " 0.00048474634633353833,\n",
       " 0.0005034878337107944,\n",
       " 0.0004839341507723732,\n",
       " 0.00048695292344732704,\n",
       " 0.0004961590513635269,\n",
       " 0.000538436632548148,\n",
       " 0.0004827334734980636,\n",
       " 0.0005104189492321184,\n",
       " 0.0004847586696102606,\n",
       " 0.0005053487659157892,\n",
       " 0.00048692068934647303,\n",
       " 0.0004923656552993459,\n",
       " 0.00048550957714442005,\n",
       " 0.0004840083661461528,\n",
       " 0.0004997196504002969,\n",
       " 0.0004910648220272764,\n",
       " 0.00048532177070080237,\n",
       " 0.00048344574834789937,\n",
       " 0.0005064425831486247,\n",
       " 0.0004905083820327411,\n",
       " 0.0004831009533226325,\n",
       " 0.0005039860070543405,\n",
       " 0.00048131571534319414,\n",
       " 0.0004852927856075364,\n",
       " 0.0004811211797061829,\n",
       " 0.0004811977204862647,\n",
       " 0.00048065773187915434,\n",
       " 0.0004792347676923821,\n",
       " 0.0004800381052384671,\n",
       " 0.00048154580493671347,\n",
       " 0.0004862814692856768,\n",
       " 0.0004806538083142491,\n",
       " 0.00047882639834195915,\n",
       " 0.00047895542302175476,\n",
       " 0.000476759350489768,\n",
       " 0.00047762949319425066,\n",
       " 0.0004950220270992402,\n",
       " 0.0004777073483368674,\n",
       " 0.0004789647354926741,\n",
       " 0.0004798707010050469,\n",
       " 0.000482418070163388,\n",
       " 0.00047684393934718664,\n",
       " 0.00048152173772771464,\n",
       " 0.00048748109120592725,\n",
       " 0.0004856964090202809,\n",
       " 0.00047656762703578913,\n",
       " 0.000489770241174712,\n",
       " 0.00047908390605262046,\n",
       " 0.0004763783199472065,\n",
       " 0.0004787120756993737,\n",
       " 0.0004777305396905174,\n",
       " 0.00047709820630257406,\n",
       " 0.00047816036216963113,\n",
       " 0.00047624112087208515,\n",
       " 0.00047871601430524337,\n",
       " 0.00047808480293908933,\n",
       " 0.0004756306538314244,\n",
       " 0.0004761401979060586,\n",
       " 0.0004776996287986005,\n",
       " 0.0004785357410212807,\n",
       " 0.0004757160492331421,\n",
       " 0.0004761090928826853,\n",
       " 0.000475771443758345,\n",
       " 0.00047899238556321403,\n",
       " 0.0004756091314615227,\n",
       " 0.0004766410886693949,\n",
       " 0.00047439791952729745,\n",
       " 0.00047866577701244443,\n",
       " 0.0004786954660432049,\n",
       " 0.0004793384753708724,\n",
       " 0.000475622537634479,\n",
       " 0.0004813508091352061,\n",
       " 0.0004741403493364534,\n",
       " 0.00048300572704994965,\n",
       " 0.0004740226183061325,\n",
       " 0.0004883189695358097,\n",
       " 0.0004964116715018333,\n",
       " 0.0004729343767454544,\n",
       " 0.0004733388892552773,\n",
       " 0.00047321045796537906,\n",
       " 0.00047526249442867075,\n",
       " 0.000477832163336879,\n",
       " 0.0004762670979758099,\n",
       " 0.0004738955262004208,\n",
       " 0.0004746891583655945,\n",
       " 0.00047537463159449337,\n",
       " 0.00047485784868890786,\n",
       " 0.0004798546556789551,\n",
       " 0.0004737679970584848,\n",
       " 0.00047387440695238027,\n",
       " 0.00047900818118630414,\n",
       " 0.00047329173774984367,\n",
       " 0.0004759151466039609,\n",
       " 0.00047406552266388187,\n",
       " 0.0004755229718078714,\n",
       " 0.0004733090758213986,\n",
       " 0.0004723978895592596,\n",
       " 0.0004724528261525818,\n",
       " 0.0004784497786721873,\n",
       " 0.0004721475594702165,\n",
       " 0.00047304884842287964,\n",
       " 0.00047453539328185207,\n",
       " 0.00047368488609836806,\n",
       " 0.00047230333893103074,\n",
       " 0.0004764827747622501,\n",
       " 0.00047475138111971677,\n",
       " 0.00047388145411346965,\n",
       " 0.0004741560710718536,\n",
       " 0.00047253910537663684,\n",
       " 0.00047271067741207554,\n",
       " 0.00047219532146990507,\n",
       " 0.0004721190181101254,\n",
       " 0.00047431033618893333,\n",
       " 0.00047151994030287907,\n",
       " 0.0004812304134804474,\n",
       " 0.00047235536381616474,\n",
       " 0.00047662829905619625,\n",
       " 0.00047149454351563987,\n",
       " 0.0004727693295031098,\n",
       " 0.0004746093646574241,\n",
       " 0.0004717464093589196,\n",
       " 0.00047209308226037097,\n",
       " 0.0004729219524504612,\n",
       " 0.0004711092930202516,\n",
       " 0.0004743878144306509,\n",
       " 0.0004740023167528283,\n",
       " 0.0004727260756503553,\n",
       " 0.00047357236816461247,\n",
       " 0.0004703633889417402,\n",
       " 0.0004782961334393881,\n",
       " 0.0004708913420006154,\n",
       " 0.00047157920824754916,\n",
       " 0.0004719571629695473,\n",
       " 0.00047346695649497846,\n",
       " 0.00047241794786569396,\n",
       " 0.0004712988190713471,\n",
       " 0.0004712887338279663,\n",
       " 0.00047065526560081,\n",
       " 0.0004717911029030045,\n",
       " 0.000471128246212267,\n",
       " 0.00047501897599948925,\n",
       " 0.00047273367506601283,\n",
       " 0.00047217378586360997,\n",
       " 0.0004709158352889088,\n",
       " 0.0004722731560942522,\n",
       " 0.00047188801996379386,\n",
       " 0.000471545257193789,\n",
       " 0.0004706877706689648,\n",
       " 0.0004705894073887195,\n",
       " 0.00047044467436004603,\n",
       " 0.0004720907489526009,\n",
       " 0.0004710570857781347,\n",
       " 0.00047165022504282606,\n",
       " 0.00047229084162334176,\n",
       " 0.0004711223925260547,\n",
       " 0.00047252245010267883,\n",
       " 0.0004708901526015118,\n",
       " 0.00047115186085878633,\n",
       " 0.00047063929957125926,\n",
       " 0.0004706889891048543,\n",
       " 0.0004708534722501795,\n",
       " 0.00047059750532346537,\n",
       " 0.00047378789381862896,\n",
       " 0.000470756576974108,\n",
       " 0.0004702444725847739,\n",
       " 0.0004725047945242452,\n",
       " 0.0004712930307298488,\n",
       " 0.00047071853030290837,\n",
       " 0.00047050301217521216,\n",
       " 0.0004705893838706847,\n",
       " 0.00047102229476489953,\n",
       " 0.000470734486739328,\n",
       " 0.0004704750107735462,\n",
       " 0.00047110412707141006,\n",
       " 0.00047280278764052504,\n",
       " 0.00047252143286982283,\n",
       " 0.00047094522403880526,\n",
       " 0.0004715736537294067,\n",
       " 0.00047065330556490023,\n",
       " 0.0004713630386857005,\n",
       " 0.00047050351659706454,\n",
       " 0.0004709198498058647,\n",
       " 0.0004701268372750338,\n",
       " 0.00047121169221775607,\n",
       " 0.00047055122933292016,\n",
       " 0.00047052344343550433,\n",
       " 0.0004707858818158074,\n",
       " 0.00047047398536606913,\n",
       " 0.00047251104220688995,\n",
       " 0.0004707022096025883,\n",
       " 0.0004702840188094045]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.test_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = DeepPotential().cuda()\n",
    "test_model.load_state_dict(torch.load('ModelCheckpoints/c7o2h10/epoch_280'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.model.children()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
